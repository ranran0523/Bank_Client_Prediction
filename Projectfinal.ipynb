{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data.csv')     #read the data.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_future=pd.read_csv('futures.csv')  #read the future.csv.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ranra\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # to import csv and for data manipulation\n",
    "import matplotlib.pyplot as plt # to plot graph\n",
    "import seaborn as sns # for intractve graphs\n",
    "import numpy as np # for linear algebra\n",
    "import datetime # to dela with date and time\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler # for preprocessing the data\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest classifier\n",
    "from sklearn.tree import DecisionTreeClassifier # for Decision Tree classifier\n",
    "from sklearn.svm import SVC # for SVM classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split # to split the data\n",
    "from sklearn.cross_validation import KFold # For cross vbalidation\n",
    "from sklearn.model_selection import GridSearchCV # for tunnig hyper parameter it will use all combination of given parameters\n",
    "from sklearn.model_selection import RandomizedSearchCV # same for tunning hyper parameter but will use random combinations of parameters\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40181 entries, 0 to 40180\n",
      "Data columns (total 16 columns):\n",
      "age               40181 non-null int64\n",
      "job               40181 non-null object\n",
      "marital           40181 non-null object\n",
      "education         40181 non-null object\n",
      "default           40181 non-null object\n",
      "housing           40181 non-null object\n",
      "loan              40181 non-null object\n",
      "contact           40181 non-null object\n",
      "day_of_week       40181 non-null object\n",
      "campaign          40181 non-null int64\n",
      "pdays             40181 non-null int64\n",
      "poutcome          40181 non-null object\n",
      "cons_price_idx    40181 non-null float64\n",
      "cons_conf_idx     40181 non-null float64\n",
      "prime_rate        40181 non-null float64\n",
      "y                 40181 non-null object\n",
      "dtypes: float64(3), int64(3), object(10)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20b1edcfba8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(\"y\",data=data) # check the y distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform categorical data to numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a class to transform categorical data to numerical data from 0..n\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=MultiColumnLabelEncoder(columns = ['job','marital','education','default','housing','loan','contact','day_of_week','poutcome','y']).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_future=MultiColumnLabelEncoder(columns = ['job','marital','education','default','housing','loan','contact','day_of_week','poutcome']).fit_transform(data_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>prime_rate</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  housing  loan  contact  day_of_week  \\\n",
       "0   56    3        1          0        0        0     0        1            1   \n",
       "1   57    7        1          3        1        0     0        1            1   \n",
       "2   37    7        1          3        0        2     0        1            1   \n",
       "3   40    0        1          1        0        0     0        1            1   \n",
       "4   56    7        1          3        0        0     2        1            1   \n",
       "\n",
       "   campaign  pdays  poutcome  cons_price_idx  cons_conf_idx  prime_rate  y  \n",
       "0         1    999         1          93.994          -36.4       4.857  0  \n",
       "1         1    999         1          93.994          -36.4       4.857  0  \n",
       "2         1    999         1          93.994          -36.4       4.857  0  \n",
       "3         1    999         1          93.994          -36.4       4.857  0  \n",
       "4         1    999         1          93.994          -36.4       4.857  0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>prime_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  housing  loan  contact  day_of_week  \\\n",
       "0   42    1        1          2        1        0     0        1            1   \n",
       "1   41    4        1          1        0        0     0        1            1   \n",
       "2   34    9        1          3        0        0     0        1            1   \n",
       "3   54    5        1          3        1        0     0        1            1   \n",
       "4   48    1        1          0        0        2     0        1            1   \n",
       "\n",
       "   campaign  pdays  poutcome  cons_price_idx  cons_conf_idx  prime_rate  \n",
       "0         1    999         1          93.994          -36.4       4.857  \n",
       "1         2    999         1          93.994          -36.4       4.857  \n",
       "2         1    999         1          93.994          -36.4       4.857  \n",
       "3         1    999         1          93.994          -36.4       4.857  \n",
       "4         1    999         1          93.994          -36.4       4.857  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_future.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20b1f19a8d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the difference in distributions between 0 and 1\n",
    "client_subscribed = data[data[\"y\"]==1]\n",
    "client_not_subscribed = data[data[\"y\"]==0]\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.subplot(121)\n",
    "client_subscribed.age.plot.hist(title=\"client_subscribed\")\n",
    "plt.subplot(122)\n",
    "client_not_subscribed.age.plot.hist(title=\"client_not_subscribed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of no 89.75635250491526\n",
      "percentage of yes 10.243647495084742\n"
     ]
    }
   ],
   "source": [
    "# check in the number of Percentage\n",
    "Count_no = len(data[data[\"y\"]==0]) # not subscribed by 0\n",
    "Count_yes = len(data[data[\"y\"]==1]) # yes by 1\n",
    "Percentage_of_no = Count_no/(Count_no+Count_yes)\n",
    "print(\"percentage of no\",Percentage_of_no*100)\n",
    "Percentage_of_yes= Count_yes/(Count_no+Count_yes)\n",
    "print(\"percentage of yes\",Percentage_of_yes*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle imblanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_majority=data[data.y==0]\n",
    "data_minority=data[data.y==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the minority of data up to same amounts with majority(duplicate randomly from existed data)\n",
    "data_minority_upsampled = resample(data_minority,replace=True,n_samples=36065,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_upsampled is the balanced data\n",
    "data_upsampled = pd.concat([data_majority,data_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20b1c36dbe0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(\"y\",data=data_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(data_upsampled.drop('y',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = scaler.transform(data_upsampled.drop('y',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data=pd.DataFrame(scaled_features,columns=data_upsampled.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>prime_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.295145</td>\n",
       "      <td>-0.230426</td>\n",
       "      <td>-0.331518</td>\n",
       "      <td>-1.824056</td>\n",
       "      <td>-0.436215</td>\n",
       "      <td>-1.106064</td>\n",
       "      <td>-0.448175</td>\n",
       "      <td>1.609177</td>\n",
       "      <td>-0.743612</td>\n",
       "      <td>-0.56567</td>\n",
       "      <td>0.354655</td>\n",
       "      <td>0.032781</td>\n",
       "      <td>0.815485</td>\n",
       "      <td>0.705839</td>\n",
       "      <td>1.002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.378211</td>\n",
       "      <td>0.876473</td>\n",
       "      <td>-0.331518</td>\n",
       "      <td>-0.420612</td>\n",
       "      <td>2.291028</td>\n",
       "      <td>-1.106064</td>\n",
       "      <td>-0.448175</td>\n",
       "      <td>1.609177</td>\n",
       "      <td>-0.743612</td>\n",
       "      <td>-0.56567</td>\n",
       "      <td>0.354655</td>\n",
       "      <td>0.032781</td>\n",
       "      <td>0.815485</td>\n",
       "      <td>0.705839</td>\n",
       "      <td>1.002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.283114</td>\n",
       "      <td>0.876473</td>\n",
       "      <td>-0.331518</td>\n",
       "      <td>-0.420612</td>\n",
       "      <td>-0.436215</td>\n",
       "      <td>0.926014</td>\n",
       "      <td>-0.448175</td>\n",
       "      <td>1.609177</td>\n",
       "      <td>-0.743612</td>\n",
       "      <td>-0.56567</td>\n",
       "      <td>0.354655</td>\n",
       "      <td>0.032781</td>\n",
       "      <td>0.815485</td>\n",
       "      <td>0.705839</td>\n",
       "      <td>1.002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.033915</td>\n",
       "      <td>-1.060600</td>\n",
       "      <td>-0.331518</td>\n",
       "      <td>-1.356241</td>\n",
       "      <td>-0.436215</td>\n",
       "      <td>-1.106064</td>\n",
       "      <td>-0.448175</td>\n",
       "      <td>1.609177</td>\n",
       "      <td>-0.743612</td>\n",
       "      <td>-0.56567</td>\n",
       "      <td>0.354655</td>\n",
       "      <td>0.032781</td>\n",
       "      <td>0.815485</td>\n",
       "      <td>0.705839</td>\n",
       "      <td>1.002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.295145</td>\n",
       "      <td>0.876473</td>\n",
       "      <td>-0.331518</td>\n",
       "      <td>-0.420612</td>\n",
       "      <td>-0.436215</td>\n",
       "      <td>-1.106064</td>\n",
       "      <td>2.332509</td>\n",
       "      <td>1.609177</td>\n",
       "      <td>-0.743612</td>\n",
       "      <td>-0.56567</td>\n",
       "      <td>0.354655</td>\n",
       "      <td>0.032781</td>\n",
       "      <td>0.815485</td>\n",
       "      <td>0.705839</td>\n",
       "      <td>1.002379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       job   marital  education   default   housing      loan  \\\n",
       "0  1.295145 -0.230426 -0.331518  -1.824056 -0.436215 -1.106064 -0.448175   \n",
       "1  1.378211  0.876473 -0.331518  -0.420612  2.291028 -1.106064 -0.448175   \n",
       "2 -0.283114  0.876473 -0.331518  -0.420612 -0.436215  0.926014 -0.448175   \n",
       "3 -0.033915 -1.060600 -0.331518  -1.356241 -0.436215 -1.106064 -0.448175   \n",
       "4  1.295145  0.876473 -0.331518  -0.420612 -0.436215 -1.106064  2.332509   \n",
       "\n",
       "    contact  day_of_week  campaign     pdays  poutcome  cons_price_idx  \\\n",
       "0  1.609177    -0.743612  -0.56567  0.354655  0.032781        0.815485   \n",
       "1  1.609177    -0.743612  -0.56567  0.354655  0.032781        0.815485   \n",
       "2  1.609177    -0.743612  -0.56567  0.354655  0.032781        0.815485   \n",
       "3  1.609177    -0.743612  -0.56567  0.354655  0.032781        0.815485   \n",
       "4  1.609177    -0.743612  -0.56567  0.354655  0.032781        0.815485   \n",
       "\n",
       "   cons_conf_idx  prime_rate  \n",
       "0       0.705839    1.002379  \n",
       "1       0.705839    1.002379  \n",
       "2       0.705839    1.002379  \n",
       "3       0.705839    1.002379  \n",
       "4       0.705839    1.002379  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data_upsampled[['age','job','marital','education','default','housing','loan','contact','day_of_week','campaign','pdays','poutcome','cons_price_idx','cons_conf_idx','prime_rate']]\n",
    "y=data_upsampled['y']\n",
    "x_future=data_future[['age','job','marital','education','default','housing','loan','contact','day_of_week','campaign','pdays','poutcome','cons_price_idx','cons_conf_idx','prime_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for making comparsion with balanced data\n",
    "x1=data[['age','job','marital','education','default','housing','loan','contact','day_of_week','campaign','pdays','poutcome','cons_price_idx','cons_conf_idx','prime_rate']]\n",
    "y1=data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1,y1, test_size=0.20,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x1_train,y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95      7211\n",
      "          1       0.63      0.19      0.29       826\n",
      "\n",
      "avg / total       0.88      0.91      0.88      8037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imbalanced data doing classification\n",
    "predictions1=logmodel.predict(x1_test)\n",
    "print(classification_report(y1_test,predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.20,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.75      0.73      7245\n",
      "          1       0.74      0.70      0.72      7181\n",
      "\n",
      "avg / total       0.73      0.73      0.72     14426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions=logmodel.predict(x_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNearesetNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scaled_data[['age','job','marital','education','default','housing','loan','contact','day_of_week','campaign','pdays','poutcome','cons_price_idx','cons_conf_idx','prime_rate']]\n",
    "y=data_upsampled['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(scaled_data,data_upsampled['y'], test_size=0.20,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.91      0.94      7245\n",
      "          1       0.91      0.99      0.95      7181\n",
      "\n",
      "avg / total       0.95      0.95      0.95     14426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "edtree=DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data_upsampled[['age','job','marital','education','default','housing','loan','contact','day_of_week','campaign','pdays','poutcome','cons_price_idx','cons_conf_idx','prime_rate']]\n",
    "y=data_upsampled['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edtree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = edtree.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.89      0.94      7245\n",
      "          1       0.90      1.00      0.95      7181\n",
      "\n",
      "avg / total       0.95      0.94      0.94     14426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.94      0.97      7245\n",
      "          1       0.94      1.00      0.97      7181\n",
      "\n",
      "avg / total       0.97      0.97      0.97     14426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SupportVectorMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.86      0.85      7245\n",
      "          1       0.85      0.83      0.84      7181\n",
      "\n",
      "avg / total       0.84      0.84      0.84     14426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10,100,1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.9563815960488693, total= 2.1min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.9559656875487392, total= 2.1min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  6.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.1, gamma=1, kernel=rbf, score=0.907663512529895, total= 2.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.7444762152326488, total= 2.3min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.7467117234208475, total= 2.3min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=rbf, score=0.74669855464282, total= 2.3min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.7363140109175982, total= 1.5min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.7362100337925657, total= 1.5min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=rbf, score=0.7342206509306437, total= 1.5min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.7172342084741357, total= 1.5min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.7208214192877567, total= 1.5min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=rbf, score=0.7137360923364875, total= 1.5min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.7210813621003379, total= 1.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.7259682869768651, total= 1.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=rbf, score=0.7158157429551836, total= 1.4min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.9870548479334547, total= 3.6min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.9873147907460359, total= 3.6min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV]  C=1, gamma=1, kernel=rbf, score=0.9876260788187584, total= 3.6min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.859059007018456, total= 2.8min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.8599428125812322, total= 2.9min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV]  C=1, gamma=0.1, kernel=rbf, score=0.8544764479567433, total= 2.8min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.7440083181700026, total= 1.8min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.7417208214192877, total= 1.8min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV]  C=1, gamma=0.01, kernel=rbf, score=0.741655401892482, total= 2.0min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.724876527164024, total= 1.6min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.7310631661034572, total= 1.5min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV]  C=1, gamma=0.001, kernel=rbf, score=0.7214827908911303, total= 1.5min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.7172342084741357, total= 1.3min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.7207694307252405, total= 1.3min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=rbf, score=0.7137360923364875, total= 1.3min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.9876787106836497, total= 3.3min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.9879906420587471, total= 3.3min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV]  C=10, gamma=1, kernel=rbf, score=0.9879380264115628, total= 3.3min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.9231089160384716, total= 5.7min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.9246685729139589, total= 6.7min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV]  C=10, gamma=0.1, kernel=rbf, score=0.9159821150046792, total= 5.7min\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.7589290356121653, total= 2.9min\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.7579412529243567, total= 2.8min\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV]  C=10, gamma=0.01, kernel=rbf, score=0.7563169387542893, total= 2.9min\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7377177021055368, total= 1.9min\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.735014296854692, total= 1.8min\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV]  C=10, gamma=0.001, kernel=rbf, score=0.7352084849745243, total= 1.8min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.7172342084741357, total= 1.4min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.7207694307252405, total= 1.4min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV]  C=10, gamma=0.0001, kernel=rbf, score=0.7137360923364875, total= 1.4min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.9877306992461659, total= 3.3min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.9880946191837796, total= 3.4min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV]  C=100, gamma=1, kernel=rbf, score=0.9878860351460954, total= 3.3min\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.9303353262282298, total= 7.3min\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.9318429945412009, total= 7.4min\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV]  C=100, gamma=0.1, kernel=rbf, score=0.9255485078506811, total= 7.4min\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.7936054068105017, total= 7.8min\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.7931375097478555, total= 7.8min\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV]  C=100, gamma=0.01, kernel=rbf, score=0.7921909119267962, total= 7.7min\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.7409929815440603, total= 4.2min\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.7378736677930855, total= 4.2min\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV]  C=100, gamma=0.001, kernel=rbf, score=0.7391598211500467, total= 4.3min\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.7181700025994281, total= 2.0min\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.7269560696646737, total= 1.7min\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV]  C=100, gamma=0.0001, kernel=rbf, score=0.7151398565041073, total= 1.8min\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.9877306992461659, total= 3.3min\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.9880946191837796, total= 3.4min\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV]  C=1000, gamma=1, kernel=rbf, score=0.9879380264115628, total= 3.3min\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.9310631661034572, total= 7.6min\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.9313231089160384, total= 7.7min\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=rbf, score=0.9260164292398877, total= 7.6min\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.8359240966987262, total=43.9min\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.8361320509487913, total=43.0min\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV]  C=1000, gamma=0.01, kernel=rbf, score=0.8322241863366955, total=42.6min\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.7436963867949051, total=17.2min\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.7443722381076163, total=16.3min\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV]  C=1000, gamma=0.001, kernel=rbf, score=0.7441509826349173, total=17.5min\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.731219131791006, total= 4.2min\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.7368858851052769, total= 3.5min\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=rbf, score=0.7262139960486639, total= 4.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 444.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99      7245\n",
      "          1       0.99      1.00      0.99      7181\n",
      "\n",
      "avg / total       0.99      0.99      0.99     14426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scaled_data[['age','job','marital','education','default','housing','loan','contact','day_of_week','campaign','pdays','poutcome','cons_price_idx','cons_conf_idx','prime_rate']]\n",
    "y=data_upsampled['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57704, 15)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14426, 15)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.contrib.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = models.Sequential()\n",
    "dnn.add( layers.Dense(input_dim=15, units=8, activation='relu' ))\n",
    "dnn.add( layers.Dense(units=8, activation='relu' ))\n",
    "dnn.add( layers.Dense(units=8, activation='relu' ))\n",
    "dnn.add( layers.Dense(units=1, activation='sigmoid' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "57704/57704 [==============================] - 1s 18us/step - loss: 0.5984 - acc: 0.6756\n",
      "Epoch 2/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5511 - acc: 0.7314\n",
      "Epoch 3/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5448 - acc: 0.7344\n",
      "Epoch 4/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5410 - acc: 0.7365\n",
      "Epoch 5/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5390 - acc: 0.7381\n",
      "Epoch 6/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5379 - acc: 0.7384\n",
      "Epoch 7/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5370 - acc: 0.7385\n",
      "Epoch 8/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5364 - acc: 0.7379\n",
      "Epoch 9/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5361 - acc: 0.7380\n",
      "Epoch 10/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5355 - acc: 0.7374\n",
      "Epoch 11/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5351 - acc: 0.7378\n",
      "Epoch 12/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5346 - acc: 0.7388\n",
      "Epoch 13/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5340 - acc: 0.7394\n",
      "Epoch 14/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5337 - acc: 0.7400\n",
      "Epoch 15/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5335 - acc: 0.7405\n",
      "Epoch 16/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5330 - acc: 0.7409\n",
      "Epoch 17/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5323 - acc: 0.7405\n",
      "Epoch 18/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5319 - acc: 0.7412\n",
      "Epoch 19/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5314 - acc: 0.7418\n",
      "Epoch 20/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5311 - acc: 0.7413\n",
      "Epoch 21/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5306 - acc: 0.7419\n",
      "Epoch 22/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5302 - acc: 0.7417\n",
      "Epoch 23/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5301 - acc: 0.7428\n",
      "Epoch 24/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5298 - acc: 0.7427\n",
      "Epoch 25/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5295 - acc: 0.7430\n",
      "Epoch 26/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5292 - acc: 0.7435\n",
      "Epoch 27/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5290 - acc: 0.7433\n",
      "Epoch 28/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5288 - acc: 0.7437\n",
      "Epoch 29/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5286 - acc: 0.7444\n",
      "Epoch 30/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5283 - acc: 0.7447\n",
      "Epoch 31/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5280 - acc: 0.7437\n",
      "Epoch 32/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5277 - acc: 0.7446\n",
      "Epoch 33/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5275 - acc: 0.7459\n",
      "Epoch 34/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5272 - acc: 0.7452\n",
      "Epoch 35/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5268 - acc: 0.7449\n",
      "Epoch 36/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5267 - acc: 0.7444\n",
      "Epoch 37/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5265 - acc: 0.7454\n",
      "Epoch 38/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5262 - acc: 0.7455\n",
      "Epoch 39/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5260 - acc: 0.7464\n",
      "Epoch 40/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5258 - acc: 0.7463\n",
      "Epoch 41/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5255 - acc: 0.7462\n",
      "Epoch 42/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5253 - acc: 0.7469\n",
      "Epoch 43/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5251 - acc: 0.7468\n",
      "Epoch 44/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5249 - acc: 0.7473\n",
      "Epoch 45/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5248 - acc: 0.7471\n",
      "Epoch 46/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5243 - acc: 0.7474\n",
      "Epoch 47/500\n",
      "57704/57704 [==============================] - 1s 14us/step - loss: 0.5244 - acc: 0.7464: 0s - loss: 0.535\n",
      "Epoch 48/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5240 - acc: 0.7470\n",
      "Epoch 49/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5240 - acc: 0.7473\n",
      "Epoch 50/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5238 - acc: 0.7481\n",
      "Epoch 51/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5236 - acc: 0.7475\n",
      "Epoch 52/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5233 - acc: 0.7487\n",
      "Epoch 53/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5233 - acc: 0.7488\n",
      "Epoch 54/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5231 - acc: 0.7492\n",
      "Epoch 55/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5229 - acc: 0.7495\n",
      "Epoch 56/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5226 - acc: 0.7505\n",
      "Epoch 57/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5222 - acc: 0.7511\n",
      "Epoch 58/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5220 - acc: 0.7508\n",
      "Epoch 59/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5219 - acc: 0.7501\n",
      "Epoch 60/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5213 - acc: 0.7510\n",
      "Epoch 61/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5214 - acc: 0.7519\n",
      "Epoch 62/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5215 - acc: 0.7512\n",
      "Epoch 63/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5211 - acc: 0.7512\n",
      "Epoch 64/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5208 - acc: 0.7524\n",
      "Epoch 65/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5210 - acc: 0.7513\n",
      "Epoch 66/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5207 - acc: 0.7523\n",
      "Epoch 67/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5202 - acc: 0.7525\n",
      "Epoch 68/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5201 - acc: 0.7529\n",
      "Epoch 69/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5205 - acc: 0.7524\n",
      "Epoch 70/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5200 - acc: 0.7514\n",
      "Epoch 71/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5199 - acc: 0.7524\n",
      "Epoch 72/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5198 - acc: 0.7525\n",
      "Epoch 73/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5196 - acc: 0.7521\n",
      "Epoch 74/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5197 - acc: 0.7521\n",
      "Epoch 75/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5195 - acc: 0.7522\n",
      "Epoch 76/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5194 - acc: 0.7529\n",
      "Epoch 77/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5195 - acc: 0.7516\n",
      "Epoch 78/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5194 - acc: 0.7522\n",
      "Epoch 79/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5192 - acc: 0.7520\n",
      "Epoch 80/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5194 - acc: 0.7525\n",
      "Epoch 81/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5188 - acc: 0.7526\n",
      "Epoch 82/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5189 - acc: 0.7521\n",
      "Epoch 83/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5191 - acc: 0.7520\n",
      "Epoch 84/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5189 - acc: 0.7520\n",
      "Epoch 85/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5190 - acc: 0.7519\n",
      "Epoch 86/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5186 - acc: 0.7523\n",
      "Epoch 87/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5187 - acc: 0.7521\n",
      "Epoch 88/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5184 - acc: 0.7524\n",
      "Epoch 89/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5185 - acc: 0.7525\n",
      "Epoch 90/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5182 - acc: 0.7532\n",
      "Epoch 91/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5181 - acc: 0.7519\n",
      "Epoch 92/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5182 - acc: 0.7533\n",
      "Epoch 93/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5180 - acc: 0.7521\n",
      "Epoch 94/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5179 - acc: 0.7537\n",
      "Epoch 95/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5178 - acc: 0.7532\n",
      "Epoch 96/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5181 - acc: 0.7531\n",
      "Epoch 97/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5177 - acc: 0.7529\n",
      "Epoch 98/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5178 - acc: 0.7529\n",
      "Epoch 99/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5179 - acc: 0.7522\n",
      "Epoch 100/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5178 - acc: 0.7535\n",
      "Epoch 101/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5178 - acc: 0.7538\n",
      "Epoch 102/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5178 - acc: 0.7541\n",
      "Epoch 103/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5175 - acc: 0.7528\n",
      "Epoch 104/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5178 - acc: 0.7528\n",
      "Epoch 105/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5174 - acc: 0.7534\n",
      "Epoch 106/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5178 - acc: 0.7528\n",
      "Epoch 107/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5174 - acc: 0.7539\n",
      "Epoch 108/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5176 - acc: 0.7526\n",
      "Epoch 109/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5176 - acc: 0.7528\n",
      "Epoch 110/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5172 - acc: 0.7529\n",
      "Epoch 111/500\n",
      "57704/57704 [==============================] - 1s 15us/step - loss: 0.5173 - acc: 0.7529\n",
      "Epoch 112/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5177 - acc: 0.7532\n",
      "Epoch 113/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5174 - acc: 0.7524\n",
      "Epoch 114/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5175 - acc: 0.7532\n",
      "Epoch 115/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5174 - acc: 0.7521\n",
      "Epoch 116/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5172 - acc: 0.7528\n",
      "Epoch 117/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5172 - acc: 0.7534\n",
      "Epoch 118/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5172 - acc: 0.7533\n",
      "Epoch 119/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5172 - acc: 0.7539\n",
      "Epoch 120/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5176 - acc: 0.7534\n",
      "Epoch 121/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5170 - acc: 0.7522\n",
      "Epoch 122/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5170 - acc: 0.7533\n",
      "Epoch 123/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5172 - acc: 0.7535\n",
      "Epoch 124/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5170 - acc: 0.7545\n",
      "Epoch 125/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5169 - acc: 0.7538\n",
      "Epoch 126/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5169 - acc: 0.7535\n",
      "Epoch 127/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5170 - acc: 0.7536\n",
      "Epoch 128/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5169 - acc: 0.7536\n",
      "Epoch 129/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5171 - acc: 0.7532\n",
      "Epoch 130/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5168 - acc: 0.7532\n",
      "Epoch 131/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5169 - acc: 0.7528\n",
      "Epoch 132/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5169 - acc: 0.7538\n",
      "Epoch 133/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5170 - acc: 0.7536\n",
      "Epoch 134/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5169 - acc: 0.7527\n",
      "Epoch 135/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5166 - acc: 0.7528\n",
      "Epoch 136/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5169 - acc: 0.7532\n",
      "Epoch 137/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5169 - acc: 0.7535\n",
      "Epoch 138/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5168 - acc: 0.7533\n",
      "Epoch 139/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5167 - acc: 0.7524\n",
      "Epoch 140/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5168 - acc: 0.7537\n",
      "Epoch 141/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5166 - acc: 0.7540\n",
      "Epoch 142/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5167 - acc: 0.7537\n",
      "Epoch 143/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5166 - acc: 0.7525\n",
      "Epoch 144/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5169 - acc: 0.7535\n",
      "Epoch 145/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5166 - acc: 0.7540\n",
      "Epoch 146/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5168 - acc: 0.7529\n",
      "Epoch 147/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5168 - acc: 0.7535\n",
      "Epoch 148/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5168 - acc: 0.7535\n",
      "Epoch 149/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5166 - acc: 0.7528\n",
      "Epoch 150/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5165 - acc: 0.7533\n",
      "Epoch 151/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5172 - acc: 0.7528\n",
      "Epoch 152/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5171 - acc: 0.7533\n",
      "Epoch 153/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5171 - acc: 0.7536\n",
      "Epoch 154/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5170 - acc: 0.7534\n",
      "Epoch 155/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5166 - acc: 0.7541\n",
      "Epoch 156/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5171 - acc: 0.7538\n",
      "Epoch 157/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5167 - acc: 0.7533\n",
      "Epoch 158/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5170 - acc: 0.7534\n",
      "Epoch 159/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5163 - acc: 0.7525\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5164 - acc: 0.7521\n",
      "Epoch 161/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5165 - acc: 0.7539\n",
      "Epoch 162/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5165 - acc: 0.7532\n",
      "Epoch 163/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5165 - acc: 0.7521\n",
      "Epoch 164/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5165 - acc: 0.7531\n",
      "Epoch 165/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5164 - acc: 0.7536\n",
      "Epoch 166/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5163 - acc: 0.7533\n",
      "Epoch 167/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5163 - acc: 0.7535\n",
      "Epoch 168/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5163 - acc: 0.7530\n",
      "Epoch 169/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5161 - acc: 0.7540\n",
      "Epoch 170/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5164 - acc: 0.7539\n",
      "Epoch 171/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5165 - acc: 0.7532\n",
      "Epoch 172/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5163 - acc: 0.7540\n",
      "Epoch 173/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5160 - acc: 0.7543\n",
      "Epoch 174/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5170 - acc: 0.7535\n",
      "Epoch 175/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5164 - acc: 0.7543\n",
      "Epoch 176/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5162 - acc: 0.7534\n",
      "Epoch 177/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5162 - acc: 0.7533\n",
      "Epoch 178/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5161 - acc: 0.7546\n",
      "Epoch 179/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5165 - acc: 0.7553\n",
      "Epoch 180/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5161 - acc: 0.7531\n",
      "Epoch 181/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7546\n",
      "Epoch 182/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7540\n",
      "Epoch 183/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5160 - acc: 0.7541\n",
      "Epoch 184/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7546\n",
      "Epoch 185/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5160 - acc: 0.7546\n",
      "Epoch 186/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5161 - acc: 0.7551\n",
      "Epoch 187/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5160 - acc: 0.7532\n",
      "Epoch 188/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5161 - acc: 0.7539\n",
      "Epoch 189/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7540\n",
      "Epoch 190/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5156 - acc: 0.7552\n",
      "Epoch 191/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5164 - acc: 0.7546\n",
      "Epoch 192/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7550\n",
      "Epoch 193/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5155 - acc: 0.7545\n",
      "Epoch 194/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7540\n",
      "Epoch 195/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5161 - acc: 0.7550\n",
      "Epoch 196/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5162 - acc: 0.7539\n",
      "Epoch 197/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7543\n",
      "Epoch 198/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5162 - acc: 0.7545\n",
      "Epoch 199/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7553\n",
      "Epoch 200/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7555\n",
      "Epoch 201/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7556\n",
      "Epoch 202/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5156 - acc: 0.7544\n",
      "Epoch 203/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7541\n",
      "Epoch 204/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5157 - acc: 0.7547\n",
      "Epoch 205/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5156 - acc: 0.7545\n",
      "Epoch 206/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5160 - acc: 0.7546\n",
      "Epoch 207/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7550\n",
      "Epoch 208/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7547\n",
      "Epoch 209/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7551\n",
      "Epoch 210/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5154 - acc: 0.7553\n",
      "Epoch 211/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5160 - acc: 0.7546\n",
      "Epoch 212/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5161 - acc: 0.7552\n",
      "Epoch 213/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7542\n",
      "Epoch 214/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5160 - acc: 0.7545\n",
      "Epoch 215/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7548\n",
      "Epoch 216/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5162 - acc: 0.7541\n",
      "Epoch 217/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5156 - acc: 0.7542\n",
      "Epoch 218/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7549\n",
      "Epoch 219/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5160 - acc: 0.7554\n",
      "Epoch 220/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5163 - acc: 0.7546\n",
      "Epoch 221/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5159 - acc: 0.7548\n",
      "Epoch 222/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5162 - acc: 0.7548\n",
      "Epoch 223/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5153 - acc: 0.7546\n",
      "Epoch 224/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5155 - acc: 0.7546\n",
      "Epoch 225/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7544\n",
      "Epoch 226/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5166 - acc: 0.7539\n",
      "Epoch 227/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7553\n",
      "Epoch 228/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5161 - acc: 0.7547\n",
      "Epoch 229/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7552\n",
      "Epoch 230/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5162 - acc: 0.7541\n",
      "Epoch 231/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5157 - acc: 0.7555\n",
      "Epoch 232/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5156 - acc: 0.7555\n",
      "Epoch 233/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7554\n",
      "Epoch 234/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5166 - acc: 0.7551\n",
      "Epoch 235/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5155 - acc: 0.7555\n",
      "Epoch 236/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5154 - acc: 0.7553\n",
      "Epoch 237/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5155 - acc: 0.7561\n",
      "Epoch 238/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5153 - acc: 0.7558\n",
      "Epoch 239/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5156 - acc: 0.7560\n",
      "Epoch 240/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5154 - acc: 0.7560\n",
      "Epoch 241/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5154 - acc: 0.7557\n",
      "Epoch 242/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7547\n",
      "Epoch 243/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5156 - acc: 0.7552\n",
      "Epoch 244/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7569\n",
      "Epoch 245/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5152 - acc: 0.7563\n",
      "Epoch 246/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7567\n",
      "Epoch 247/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7540\n",
      "Epoch 248/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5154 - acc: 0.7554\n",
      "Epoch 249/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5152 - acc: 0.7549\n",
      "Epoch 250/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7548\n",
      "Epoch 251/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5153 - acc: 0.7553\n",
      "Epoch 252/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5153 - acc: 0.7558\n",
      "Epoch 253/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5150 - acc: 0.7567\n",
      "Epoch 254/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5152 - acc: 0.7557\n",
      "Epoch 255/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5151 - acc: 0.7565\n",
      "Epoch 256/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5154 - acc: 0.7548\n",
      "Epoch 257/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5152 - acc: 0.7557\n",
      "Epoch 258/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5151 - acc: 0.7555\n",
      "Epoch 259/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5169 - acc: 0.7539\n",
      "Epoch 260/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7554\n",
      "Epoch 261/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7550\n",
      "Epoch 262/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7559\n",
      "Epoch 263/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5163 - acc: 0.7550\n",
      "Epoch 264/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7556\n",
      "Epoch 265/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5156 - acc: 0.7565\n",
      "Epoch 266/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5154 - acc: 0.7558\n",
      "Epoch 267/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5161 - acc: 0.7553\n",
      "Epoch 268/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5159 - acc: 0.7561\n",
      "Epoch 269/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5162 - acc: 0.7553\n",
      "Epoch 270/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7561\n",
      "Epoch 271/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7555\n",
      "Epoch 272/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7555\n",
      "Epoch 273/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5157 - acc: 0.7565\n",
      "Epoch 274/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5160 - acc: 0.7547\n",
      "Epoch 275/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5154 - acc: 0.7555\n",
      "Epoch 276/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5160 - acc: 0.7553\n",
      "Epoch 277/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5158 - acc: 0.7554\n",
      "Epoch 278/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5153 - acc: 0.7565\n",
      "Epoch 279/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5155 - acc: 0.7548\n",
      "Epoch 280/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5155 - acc: 0.7549\n",
      "Epoch 281/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5154 - acc: 0.7559\n",
      "Epoch 282/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5152 - acc: 0.7550\n",
      "Epoch 283/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5151 - acc: 0.7568\n",
      "Epoch 284/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5150 - acc: 0.7556\n",
      "Epoch 285/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5152 - acc: 0.7558\n",
      "Epoch 286/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5151 - acc: 0.7555\n",
      "Epoch 287/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5153 - acc: 0.7550\n",
      "Epoch 288/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5151 - acc: 0.7557\n",
      "Epoch 289/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5152 - acc: 0.7562\n",
      "Epoch 290/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5150 - acc: 0.7557\n",
      "Epoch 291/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5156 - acc: 0.7554\n",
      "Epoch 292/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5154 - acc: 0.7554\n",
      "Epoch 293/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5144 - acc: 0.7563\n",
      "Epoch 294/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5141 - acc: 0.7572\n",
      "Epoch 295/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5142 - acc: 0.7577\n",
      "Epoch 296/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5147 - acc: 0.7559\n",
      "Epoch 297/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5150 - acc: 0.7558\n",
      "Epoch 298/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5145 - acc: 0.7548\n",
      "Epoch 299/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5143 - acc: 0.7566\n",
      "Epoch 300/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5143 - acc: 0.7566\n",
      "Epoch 301/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5148 - acc: 0.7560\n",
      "Epoch 302/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5141 - acc: 0.7580\n",
      "Epoch 303/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5142 - acc: 0.7567\n",
      "Epoch 304/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5142 - acc: 0.7572\n",
      "Epoch 305/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5143 - acc: 0.7570\n",
      "Epoch 306/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5141 - acc: 0.7576\n",
      "Epoch 307/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5141 - acc: 0.7570\n",
      "Epoch 308/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5140 - acc: 0.7566\n",
      "Epoch 309/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5141 - acc: 0.7564\n",
      "Epoch 310/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5135 - acc: 0.7577\n",
      "Epoch 311/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5138 - acc: 0.7560\n",
      "Epoch 312/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5136 - acc: 0.7562\n",
      "Epoch 313/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5133 - acc: 0.7581\n",
      "Epoch 314/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5137 - acc: 0.7563\n",
      "Epoch 315/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5137 - acc: 0.7566\n",
      "Epoch 316/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5135 - acc: 0.7567\n",
      "Epoch 317/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5132 - acc: 0.7567\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5138 - acc: 0.7564\n",
      "Epoch 319/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5137 - acc: 0.7570\n",
      "Epoch 320/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5135 - acc: 0.7566\n",
      "Epoch 321/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5135 - acc: 0.7564\n",
      "Epoch 322/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5137 - acc: 0.7564\n",
      "Epoch 323/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5135 - acc: 0.7570\n",
      "Epoch 324/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5143 - acc: 0.7570\n",
      "Epoch 325/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5139 - acc: 0.7567\n",
      "Epoch 326/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5136 - acc: 0.7569\n",
      "Epoch 327/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5137 - acc: 0.7567\n",
      "Epoch 328/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5138 - acc: 0.7561\n",
      "Epoch 329/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5132 - acc: 0.7577\n",
      "Epoch 330/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5134 - acc: 0.7573\n",
      "Epoch 331/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5133 - acc: 0.7570\n",
      "Epoch 332/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5133 - acc: 0.7567\n",
      "Epoch 333/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5138 - acc: 0.7570\n",
      "Epoch 334/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5141 - acc: 0.7553\n",
      "Epoch 335/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5134 - acc: 0.7564\n",
      "Epoch 336/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5134 - acc: 0.7572\n",
      "Epoch 337/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5138 - acc: 0.7566\n",
      "Epoch 338/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5131 - acc: 0.7579\n",
      "Epoch 339/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5131 - acc: 0.7576\n",
      "Epoch 340/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5136 - acc: 0.7572\n",
      "Epoch 341/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5135 - acc: 0.7569\n",
      "Epoch 342/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5133 - acc: 0.7585\n",
      "Epoch 343/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5135 - acc: 0.7566\n",
      "Epoch 344/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5133 - acc: 0.7576\n",
      "Epoch 345/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5133 - acc: 0.7585\n",
      "Epoch 346/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5134 - acc: 0.7586\n",
      "Epoch 347/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5133 - acc: 0.7580\n",
      "Epoch 348/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5143 - acc: 0.7559\n",
      "Epoch 349/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5134 - acc: 0.7579\n",
      "Epoch 350/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5131 - acc: 0.7564\n",
      "Epoch 351/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5130 - acc: 0.7573\n",
      "Epoch 352/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5139 - acc: 0.7569\n",
      "Epoch 353/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5138 - acc: 0.7571\n",
      "Epoch 354/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5137 - acc: 0.7571\n",
      "Epoch 355/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5129 - acc: 0.7575\n",
      "Epoch 356/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5134 - acc: 0.7575\n",
      "Epoch 357/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5128 - acc: 0.7586\n",
      "Epoch 358/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5132 - acc: 0.7575\n",
      "Epoch 359/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5131 - acc: 0.7588\n",
      "Epoch 360/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5130 - acc: 0.7587\n",
      "Epoch 361/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5128 - acc: 0.7576\n",
      "Epoch 362/500\n",
      "57704/57704 [==============================] - 1s 14us/step - loss: 0.5129 - acc: 0.7572\n",
      "Epoch 363/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5124 - acc: 0.7582\n",
      "Epoch 364/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5124 - acc: 0.7588\n",
      "Epoch 365/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5131 - acc: 0.7580\n",
      "Epoch 366/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5132 - acc: 0.7584\n",
      "Epoch 367/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5128 - acc: 0.7588\n",
      "Epoch 368/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5124 - acc: 0.7582\n",
      "Epoch 369/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5125 - acc: 0.7582\n",
      "Epoch 370/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5161 - acc: 0.7554\n",
      "Epoch 371/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5120 - acc: 0.7582\n",
      "Epoch 372/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5121 - acc: 0.7586\n",
      "Epoch 373/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5125 - acc: 0.7569\n",
      "Epoch 374/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5124 - acc: 0.7585\n",
      "Epoch 375/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5131 - acc: 0.7579\n",
      "Epoch 376/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5131 - acc: 0.7577\n",
      "Epoch 377/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5131 - acc: 0.7575\n",
      "Epoch 378/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5127 - acc: 0.7585\n",
      "Epoch 379/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5129 - acc: 0.7582\n",
      "Epoch 380/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5136 - acc: 0.7575\n",
      "Epoch 381/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5130 - acc: 0.7576\n",
      "Epoch 382/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5127 - acc: 0.7585\n",
      "Epoch 383/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5124 - acc: 0.7589\n",
      "Epoch 384/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5124 - acc: 0.7573\n",
      "Epoch 385/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5127 - acc: 0.7582\n",
      "Epoch 386/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5128 - acc: 0.7579\n",
      "Epoch 387/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5119 - acc: 0.7587\n",
      "Epoch 388/500\n",
      "57704/57704 [==============================] - 1s 14us/step - loss: 0.5125 - acc: 0.7591\n",
      "Epoch 389/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5123 - acc: 0.7590\n",
      "Epoch 390/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5125 - acc: 0.7590\n",
      "Epoch 391/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5121 - acc: 0.7586\n",
      "Epoch 392/500\n",
      "57704/57704 [==============================] - ETA: 0s - loss: 0.5124 - acc: 0.759 - 1s 10us/step - loss: 0.5125 - acc: 0.7594\n",
      "Epoch 393/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5135 - acc: 0.7579\n",
      "Epoch 394/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5130 - acc: 0.7585\n",
      "Epoch 395/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5125 - acc: 0.7582\n",
      "Epoch 396/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5123 - acc: 0.7587\n",
      "Epoch 397/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5126 - acc: 0.7584\n",
      "Epoch 398/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5129 - acc: 0.7578\n",
      "Epoch 399/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5125 - acc: 0.7584\n",
      "Epoch 400/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5124 - acc: 0.7594\n",
      "Epoch 401/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5126 - acc: 0.7586\n",
      "Epoch 402/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5125 - acc: 0.7584\n",
      "Epoch 403/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5126 - acc: 0.7587\n",
      "Epoch 404/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5125 - acc: 0.7587\n",
      "Epoch 405/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5123 - acc: 0.7586\n",
      "Epoch 406/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5127 - acc: 0.7579\n",
      "Epoch 407/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5121 - acc: 0.7579\n",
      "Epoch 408/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5118 - acc: 0.7598\n",
      "Epoch 409/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5126 - acc: 0.7589\n",
      "Epoch 410/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5134 - acc: 0.7591\n",
      "Epoch 411/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5122 - acc: 0.7587\n",
      "Epoch 412/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5127 - acc: 0.7582\n",
      "Epoch 413/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5122 - acc: 0.7584\n",
      "Epoch 414/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5124 - acc: 0.7584\n",
      "Epoch 415/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5120 - acc: 0.7590\n",
      "Epoch 416/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5121 - acc: 0.7593\n",
      "Epoch 417/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5124 - acc: 0.7585\n",
      "Epoch 418/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5124 - acc: 0.7589\n",
      "Epoch 419/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5126 - acc: 0.7589\n",
      "Epoch 420/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5125 - acc: 0.7576\n",
      "Epoch 421/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5125 - acc: 0.7581\n",
      "Epoch 422/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5126 - acc: 0.7588\n",
      "Epoch 423/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5124 - acc: 0.7584\n",
      "Epoch 424/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5122 - acc: 0.7588\n",
      "Epoch 425/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5119 - acc: 0.7596\n",
      "Epoch 426/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5119 - acc: 0.7590\n",
      "Epoch 427/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5116 - acc: 0.7597\n",
      "Epoch 428/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5115 - acc: 0.7594\n",
      "Epoch 429/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5121 - acc: 0.7591\n",
      "Epoch 430/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5123 - acc: 0.7586\n",
      "Epoch 431/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5113 - acc: 0.7593\n",
      "Epoch 432/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5123 - acc: 0.7582\n",
      "Epoch 433/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5119 - acc: 0.7589\n",
      "Epoch 434/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5123 - acc: 0.7585\n",
      "Epoch 435/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5118 - acc: 0.7595: 0s - loss: 0.5104 - ac\n",
      "Epoch 436/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5124 - acc: 0.7596\n",
      "Epoch 437/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5118 - acc: 0.7584\n",
      "Epoch 438/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5121 - acc: 0.7596\n",
      "Epoch 439/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5121 - acc: 0.7586\n",
      "Epoch 440/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5116 - acc: 0.7590\n",
      "Epoch 441/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5116 - acc: 0.7590\n",
      "Epoch 442/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5126 - acc: 0.7590\n",
      "Epoch 443/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5123 - acc: 0.7587\n",
      "Epoch 444/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5117 - acc: 0.7592\n",
      "Epoch 445/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5121 - acc: 0.7592\n",
      "Epoch 446/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5114 - acc: 0.7590\n",
      "Epoch 447/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5119 - acc: 0.7594\n",
      "Epoch 448/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5118 - acc: 0.7595\n",
      "Epoch 449/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5117 - acc: 0.7599\n",
      "Epoch 450/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5113 - acc: 0.7587\n",
      "Epoch 451/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5112 - acc: 0.7594\n",
      "Epoch 452/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5115 - acc: 0.7601\n",
      "Epoch 453/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5122 - acc: 0.7600\n",
      "Epoch 454/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5116 - acc: 0.7599\n",
      "Epoch 455/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5118 - acc: 0.7598\n",
      "Epoch 456/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5120 - acc: 0.7589\n",
      "Epoch 457/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5119 - acc: 0.7588\n",
      "Epoch 458/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5121 - acc: 0.7596\n",
      "Epoch 459/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5118 - acc: 0.7596\n",
      "Epoch 460/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5122 - acc: 0.7596\n",
      "Epoch 461/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5123 - acc: 0.7588\n",
      "Epoch 462/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5123 - acc: 0.7581\n",
      "Epoch 463/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5114 - acc: 0.7590\n",
      "Epoch 464/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5114 - acc: 0.7586\n",
      "Epoch 465/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5115 - acc: 0.7579\n",
      "Epoch 466/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5116 - acc: 0.7580\n",
      "Epoch 467/500\n",
      "57704/57704 [==============================] - 1s 14us/step - loss: 0.5117 - acc: 0.7589\n",
      "Epoch 468/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5118 - acc: 0.7585\n",
      "Epoch 469/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5112 - acc: 0.7601\n",
      "Epoch 470/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5111 - acc: 0.7596\n",
      "Epoch 471/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5111 - acc: 0.7597\n",
      "Epoch 472/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5112 - acc: 0.7597\n",
      "Epoch 473/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5116 - acc: 0.7597\n",
      "Epoch 474/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5112 - acc: 0.7589\n",
      "Epoch 475/500\n",
      "57704/57704 [==============================] - 1s 11us/step - loss: 0.5110 - acc: 0.7593\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5114 - acc: 0.7600\n",
      "Epoch 477/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5115 - acc: 0.7585\n",
      "Epoch 478/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5112 - acc: 0.7589\n",
      "Epoch 479/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5112 - acc: 0.7597\n",
      "Epoch 480/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5113 - acc: 0.7588\n",
      "Epoch 481/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5111 - acc: 0.7595\n",
      "Epoch 482/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5111 - acc: 0.7598\n",
      "Epoch 483/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5111 - acc: 0.7594\n",
      "Epoch 484/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5113 - acc: 0.7594\n",
      "Epoch 485/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5110 - acc: 0.7598\n",
      "Epoch 486/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5116 - acc: 0.7589\n",
      "Epoch 487/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5118 - acc: 0.7587\n",
      "Epoch 488/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5119 - acc: 0.7591\n",
      "Epoch 489/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5113 - acc: 0.7598\n",
      "Epoch 490/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5115 - acc: 0.7592\n",
      "Epoch 491/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5115 - acc: 0.7600\n",
      "Epoch 492/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5111 - acc: 0.7595\n",
      "Epoch 493/500\n",
      "57704/57704 [==============================] - 1s 13us/step - loss: 0.5108 - acc: 0.7595\n",
      "Epoch 494/500\n",
      "57704/57704 [==============================] - 1s 12us/step - loss: 0.5110 - acc: 0.7599\n",
      "Epoch 495/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5110 - acc: 0.7590\n",
      "Epoch 496/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5113 - acc: 0.7595\n",
      "Epoch 497/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5116 - acc: 0.7597\n",
      "Epoch 498/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5113 - acc: 0.7589\n",
      "Epoch 499/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5109 - acc: 0.7590\n",
      "Epoch 500/500\n",
      "57704/57704 [==============================] - 1s 10us/step - loss: 0.5115 - acc: 0.7586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20b43800c88>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn.fit(x_train, y_train, epochs=500, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dnn.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.72      0.78      8340\n",
      "          1       0.68      0.80      0.74      6086\n",
      "\n",
      "avg / total       0.77      0.76      0.76     14426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Future Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output=pd.read_csv('futures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>prime_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital    education  default housing loan    contact  \\\n",
       "0   42  blue-collar  married     basic.9y  unknown      no   no  telephone   \n",
       "1   41   management  married     basic.6y       no      no   no  telephone   \n",
       "2   34   technician  married  high.school       no      no   no  telephone   \n",
       "3   54      retired  married  high.school  unknown      no   no  telephone   \n",
       "4   48  blue-collar  married     basic.4y       no     yes   no  telephone   \n",
       "\n",
       "  day_of_week  campaign  pdays     poutcome  cons_price_idx  cons_conf_idx  \\\n",
       "0         mon         1    999  nonexistent          93.994          -36.4   \n",
       "1         mon         2    999  nonexistent          93.994          -36.4   \n",
       "2         mon         1    999  nonexistent          93.994          -36.4   \n",
       "3         mon         1    999  nonexistent          93.994          -36.4   \n",
       "4         mon         1    999  nonexistent          93.994          -36.4   \n",
       "\n",
       "   prime_rate  \n",
       "0       4.857  \n",
       "1       4.857  \n",
       "2       4.857  \n",
       "3       4.857  \n",
       "4       4.857  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best model to predict the future data(GridSearch SVM)\n",
    "future_pred=grid.predict(x_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output['y']=future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output['y'].replace(0,'no',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output['y'].replace(1,'yes',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>prime_rate</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital    education  default housing loan    contact  \\\n",
       "0   42  blue-collar  married     basic.9y  unknown      no   no  telephone   \n",
       "1   41   management  married     basic.6y       no      no   no  telephone   \n",
       "2   34   technician  married  high.school       no      no   no  telephone   \n",
       "3   54      retired  married  high.school  unknown      no   no  telephone   \n",
       "4   48  blue-collar  married     basic.4y       no     yes   no  telephone   \n",
       "\n",
       "  day_of_week  campaign  pdays     poutcome  cons_price_idx  cons_conf_idx  \\\n",
       "0         mon         1    999  nonexistent          93.994          -36.4   \n",
       "1         mon         2    999  nonexistent          93.994          -36.4   \n",
       "2         mon         1    999  nonexistent          93.994          -36.4   \n",
       "3         mon         1    999  nonexistent          93.994          -36.4   \n",
       "4         mon         1    999  nonexistent          93.994          -36.4   \n",
       "\n",
       "   prime_rate   y  \n",
       "0       4.857  no  \n",
       "1       4.857  no  \n",
       "2       4.857  no  \n",
       "3       4.857  no  \n",
       "4       4.857  no  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the future data with predciation in future_with_prediction.csv\n",
    "data_output.to_csv('futures.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for read the future_with_prediction.csv\n",
    "test=pd.read_csv('futures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>prime_rate</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital    education  default housing loan    contact  \\\n",
       "0   42  blue-collar  married     basic.9y  unknown      no   no  telephone   \n",
       "1   41   management  married     basic.6y       no      no   no  telephone   \n",
       "2   34   technician  married  high.school       no      no   no  telephone   \n",
       "3   54      retired  married  high.school  unknown      no   no  telephone   \n",
       "4   48  blue-collar  married     basic.4y       no     yes   no  telephone   \n",
       "\n",
       "  day_of_week  campaign  pdays     poutcome  cons_price_idx  cons_conf_idx  \\\n",
       "0         mon         1    999  nonexistent          93.994          -36.4   \n",
       "1         mon         2    999  nonexistent          93.994          -36.4   \n",
       "2         mon         1    999  nonexistent          93.994          -36.4   \n",
       "3         mon         1    999  nonexistent          93.994          -36.4   \n",
       "4         mon         1    999  nonexistent          93.994          -36.4   \n",
       "\n",
       "   prime_rate   y  \n",
       "0       4.857  no  \n",
       "1       4.857  no  \n",
       "2       4.857  no  \n",
       "3       4.857  no  \n",
       "4       4.857  no  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
